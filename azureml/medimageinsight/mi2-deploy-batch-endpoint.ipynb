{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# MedImageInsight for Image and Text Embeddings Deployment and Inference using Batch Endpoints\n",
    "\n",
    "This sample shows how to deploy MedImageInsight embedding type models to an batch endpoint for image and text embeddings inference. For this notebook, we use Python 3.10 - SDK v2. \n",
    "\n",
    "### Task\n",
    "MedImageInsight takes in images and/or text samples. For each image and text sample, feature embeddings are returned from the model.\n",
    " \n",
    "### Model\n",
    "The models that can perform the `embeddings` task are tagged with `embeddings`. We will use the `MedImageInsight` model in this notebook. \n",
    "\n",
    "### Inference data\n",
    "We will use a chest X-ray image and text as a sample input. \n",
    "\n",
    "### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to deploy\n",
    "3. Deploy the model to an online endpoint\n",
    "4. Test the endpoint\n",
    "5. Clean up resources - delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 1. Setup pre-requisites\n",
    "* Install [Azure ML Client library for Python](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-ml-readme?view=azure-python)\n",
    "* Connect to AzureML Workspace and authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715020627
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    ModelBatchDeployment,\n",
    "    ModelBatchDeploymentSettings,\n",
    "    Model,\n",
    "    AmlCompute,\n",
    "    Data,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    "    Environment,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_workspace = MLClient.from_config(credential)\n",
    "print(\"Workspace:\", ml_workspace)\n",
    "ml_registry = MLClient(credential, registry_name=\"azureml\")\n",
    "print(\"Registry:\", ml_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2. Pick a model to deploy\n",
    "\n",
    "Browse models in the Model Catalog in the AzureML Studio, filtering by the `embeddings` task. In this example, we use the `MedImageInsight` model. If you have opened this notebook for a different model, replace the model name accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715021120
    }
   },
   "outputs": [],
   "source": [
    "model = ml_registry.models.get(name=\"MedImageInsight\", label=\"latest\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create compute cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715024446
    }
   },
   "outputs": [],
   "source": [
    "compute_name = \"mii-batch-cluster\"\n",
    "if not any(filter(lambda m: m.name == compute_name, ml_workspace.compute.list())):\n",
    "    compute_cluster = AmlCompute(\n",
    "        name=compute_name,\n",
    "        description=\"GPU cluster compute for MedImageInsight inference\",\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        size=\"Standard_NC6s_v3\",\n",
    "    )\n",
    "    ml_workspace.compute.begin_create_or_update(compute_cluster).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 3. Deploy the model to an batch endpoint for inference\n",
    "Batch endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create batch endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715027444
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "endpoint_prefix = \"mii-batch\"\n",
    "endpoint_list = list(\n",
    "    filter(\n",
    "        lambda m: m.name.startswith(endpoint_prefix),\n",
    "        ml_workspace.batch_endpoints.list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "if endpoint_list:\n",
    "    endpoint = endpoint_list and endpoint_list[0]\n",
    "    print(\"Found existing endpoint:\", endpoint.name)\n",
    "else:\n",
    "    # Creating a unique endpoint name by including a random suffix\n",
    "    allowed_chars = string.ascii_lowercase + string.digits\n",
    "    endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "    endpoint_name = f\"{endpoint_prefix}-{endpoint_suffix}\"\n",
    "    endpoint = BatchEndpoint(\n",
    "        name=endpoint_name,\n",
    "        description=\"A batch endpoint for scoring images from MedImageInsigt.\",\n",
    "        tags={\"type\": \"medimageinsight\"},\n",
    "    )\n",
    "    ml_workspace.begin_create_or_update(endpoint).result()\n",
    "    print(f\"Created new endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Deploy MedImageInsight to batch endpoint\n",
    "\n",
    "- **max_concurrency_per_instance**: Determines the number of worker process to spawn. Each worker process loads the model into GPU. We want to use multiple worker process to maximize GPU utilization, but not exceed available GPU memory.\n",
    "- **retry_settings**: Timeout may need to be adjusted based on batch size. Larger batch size requires longer timeout; otherwise, worker process may end prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715068852
    }
   },
   "outputs": [],
   "source": [
    "deployment = ModelBatchDeployment(\n",
    "    name=\"mii-dpl\",\n",
    "    description=\"A deployment for model MedImageInsight\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    compute=compute_name,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=4,\n",
    "        mini_batch_size=1,\n",
    "        instance_count=1,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")\n",
    "ml_workspace.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715070955
    }
   },
   "outputs": [],
   "source": [
    "endpoint = ml_workspace.batch_endpoints.get(endpoint.name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_workspace.batch_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f\"The default deployment is {endpoint.defaults.deployment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4 Test the endpoint - base64 encoded image and text\n",
    "\n",
    "We will test the batch endpoint using the sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Load sample dataset\n",
    "\n",
    "Download the sample dataset using command `azcopy copy --recursive https://azuremlexampledata.blob.core.windows.net/data/healthcare-ai/ /home/azureuser/data/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715071052
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "root_dir = \"/home/azureuser/data/healthcare-ai/medimageinsight-examparameter/pngs\"\n",
    "\n",
    "png_files = glob.glob(f\"{root_dir}/**/*.png\", recursive=True)\n",
    "print(f\"Found {len(png_files)} PNG files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create the input CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Zero-Padding Batch Filenames Matters\n",
    "\n",
    "The function `write_to_csv()` will automatically create batch files with  **zero-padded numeric suffixes** (e.g., `batch_input_001.csv`, `batch_input_002.csv`, ..., `batch_input_010.csv`). \n",
    "It's essential to use that index for enumerating your batches. \n",
    "\n",
    "This ensures that files are **sorted in the correct numerical order**, rather than lexicographic string order. E.g., without padding, `batch10` would appear **before** `batch2` or `batch3` when sorting, which can lead to confusing or incorrect alignment between batch input files and batch output results. Zero-padding helps maintain predictable ordering and avoids mismatches during downstream processing or aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741716507682
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "csv_folder = \"batch_inputs\"\n",
    "sample_dataset_size = len(png_files)\n",
    "target_dataset_size = 10000\n",
    "batch_max_size = 100\n",
    "batch_count = 0\n",
    "batch = []\n",
    "\n",
    "# Pad width for filename indexing based on dataset size\n",
    "index_pad_width = len(str(target_dataset_size))\n",
    "\n",
    "# read and encode image to base64\n",
    "def read_base64_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# write batch to a CSV file\n",
    "def write_to_csv(batch_data, batch_index):\n",
    "    \"\"\"\n",
    "    Write the current batch to a CSV file with zero-padded index.\n",
    "    \"\"\"\n",
    "    filename = f\"batch_input_{str(batch_index).zfill(index_pad_width)}.csv\"\n",
    "    csv_path = os.path.join(csv_folder, filename)\n",
    "    df_input = pd.DataFrame(batch_data, columns=[\"image\", \"text\"])\n",
    "    df_input.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# remove and create folder for CSV files\n",
    "if os.path.exists(csv_folder):\n",
    "    print(f\"Removing existing folder: {csv_folder}\")\n",
    "    shutil.rmtree(csv_folder)\n",
    "\n",
    "print(f\"Creating folder: {csv_folder}\")\n",
    "os.makedirs(csv_folder)\n",
    "\n",
    "# create test dataset by repeating images from the sample dataset\n",
    "for i in range(target_dataset_size):\n",
    "    png_index = i % sample_dataset_size\n",
    "    png_file = png_files[png_index]\n",
    "    base64_image = read_base64_image(png_file)\n",
    "\n",
    "    # Append one row to the batch\n",
    "    batch.append([base64_image, \"x-ray chest anteroposterior Pneumonia\"])\n",
    "\n",
    "    # If batch is full, write it out\n",
    "    if len(batch) >= batch_max_size:\n",
    "        write_to_csv(batch, batch_count)\n",
    "        batch_count += 1\n",
    "        batch = []\n",
    "\n",
    "# Write any remaining data in the final batch\n",
    "if batch:\n",
    "    write_to_csv(batch, batch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Load the test dataset into AzureML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741716613658
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"mi2-png-dataset\"\n",
    "\n",
    "png_dataset = Data(\n",
    "    path=csv_folder,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=f\"Sample dataset consist of {target_dataset_size} PNG images with batch size of {batch_max_size}\",\n",
    "    name=dataset_name,\n",
    ")\n",
    "\n",
    "ml_workspace.data.create_or_update(png_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Verify the test dataset is uploaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715979673
    }
   },
   "outputs": [],
   "source": [
    "ml_workspace.data.get(name=dataset_name, label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Submit a job to the batch endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715996816
    }
   },
   "outputs": [],
   "source": [
    "input = Input(type=AssetTypes.URI_FILE, path=png_dataset.path)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = ml_workspace.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job progress\n",
    "ml_workspace.jobs.stream(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Download the job output\n",
    "\n",
    "MedImageInsight embeddings can be found in file `named-outputs/score/predictions.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_job = list(ml_workspace.jobs.list(parent_job_name=job.name))[0]\n",
    "scoring_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workspace.jobs.download(\n",
    "    name=scoring_job.name, download_path=\".\", output_name=\"score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Load job result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740429162012
    }
   },
   "outputs": [],
   "source": [
    "pred_csv_path = os.path.join(os.getcwd(), \"named-outputs\", \"score\", \"predictions.csv\")\n",
    "df_result = pd.read_csv(pred_csv_path, header=None)\n",
    "df_result.iloc[0]  # print first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 5. Clean up resources - delete the online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workspace.batch_endpoints.begin_delete(endpoint_name).result()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
